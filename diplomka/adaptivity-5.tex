\subsection{Automatic $hp$-adaptivity for time-dependent problems}

In the previous chapters we were concerned with the stationary problems. Let us now discuss automatic adaptivity for transient problems. Time-dependent coupled problems are challenging since one has to capture transient phenomena with sufficient accuracy, while the size of the problem must stay reasonably small. This leads to an obvious need for dynamically changing meshes for such problems. In most scientific computations, where dynamical meshes are used for time-dependent problems, data-transfer methods are necessary to move solution values between meshes for different time levels. As shown in subsection \ref{sec:data-transfer}, data-transfer methods cause additional error and in case of time-dependent problems repeated transfers (usually simple interpolation) between meshes can have disastrous consequences.

We use orthogonal projections of the solution of transient problems using dynamical $hp$-meshes obtained fully automatically by the $hp$-adaptive algorithm. With the automatic $hp$-adaptivity and dynamical meshes the question of coarsening meshes between time levels arises. Mesh derefinement is particularly important in problems where sharp fronts (internal layers) move through the domain leaving smooth solutions behind them. We propose an original coarsening algorithm suitable for $hp$-FEM based on the \textit{super-coarse solution}, which results in substantially fewer adaptive iterations.

The adaptive $hp$-FEM algorithm for time-dependent problems we use is obtained by combining the classical Rothe's method for time discretization with adaptive $hp$-FEM for the space discretization.
The Rothe's method is a natural counterpart of the widely used Method of Lines (MOL). 
Recall that the MOL performs discretization in space while keeping the time variable continuous, which leads to a system of ODEs in time. The Rothe's method, on the contrary, preserves the continuity of the spatial variable while discretizing time. In every time step, an evolutionary PDE is approximated by means of one or more time-independent ones. For one step methods (such as implicit Runge-Kutta), the number of the time-independent equations per time step is proportional to the order of accuracy of the time discretization method. For example, when employing the implicit Euler method, one has to solve just one time-independent PDE per time step:

\begin{equation}\label{rothe}
 \frac{\partial u}{\partial t} = F(t, u) \quad \Rightarrow \quad \frac{u^{n+1} - u^n}{\Delta t} = F(t^{n+1}, u^{n+1})
\end{equation}

The Rothe's method is fully equivalent to the MOL if no adaptivity in space or time takes place, but it provides a better setting for the application of spatially adaptive algorithms. The spatial discretization error can be controlled by solving the time-independent equations adaptively, and the size of 
the time step can be adjusted using standard ODE techniques \cite{deuflhard,hairer1,hairer2}.

In this subsection, first the notion of \emph{dynamical meshes} will be presented, then the refining and coarsening algorithms for time dependent problems are shown.

\paragraph{Dynamical meshes}

By ${\cal T}_m$ let us denote a uniform coarse mesh covering the computational domain 
$\Omega$. This mesh (called {\em master mesh}) is shared by the solution at all time levels, in other words all meshes can be obtained from this mesh by elementary refinements. At each time instant $t_n$ an optimal mesh is found to suit the best the solution $\bfu^n(\bfx)$. On the $(n+1)$st time level, the approximated solution $\bfu^n(\bfx)$, that has been obtained in the previous time step, is used as data. Note, however, that $\bfu^n$ is defined on a locally refined mesh that was created automatically during the $n$th time step, while the unknown $\bfu^{n+1}$ is solved adaptively starting from a coarser mesh. As a result, the meshes obtained on each time level are different, i.e., the mesh changes dynamically in time. 

As mentioned above, in transient problems the optimal meshes are on each time level obtained automatically and they can change from one time step to another, which induces need for both refining and coarsening strategies.

\subsubsection{Refining algorithm}

In Chapter \ref{ch:adapt} the goal of adaptive algorithm was to decrease the error as low as possible. On the other hand for time-dependent problems we want to sustain the space error on approximately the same level, which would result into meshes with smoothly changing number of degrees of freedom. For time-dependent problems, as well as for time-independent, the amount of elements refined in one adaptive iteration will depend on the global solution error estimate in that iteration. As described, one can drive the refining algorithm by variables $TOL$, $ERRT$, $MAX\_STEP\_NDOF$, $MAX\_NDOF$.

\subsubsection{Coarsening algorithm}

The most primitive strategy to coarsen the mesh on the next time level is to start on each level from the very coarse (master) mesh and perform the automatic adaptivity to find the optimal mesh for a particular solution $\bfu^n(\bfx)$. Although this would result in the most optimal meshes in each iteration, it is virtually impossible to carry it out due to the immense computational time demands. Moreover, a lot of work would be wasted since the solutions from two adjacent time steps usually differ only mildly even though the solution changes significantly in the whole time domain. Global derefinement would result in similar difficulties. 

We present a coarsening algorithm that prepares the mesh for the adaptive algorithm on the next time level by local derefinements. Thus, we remove only unnecessary refinements from previous time levels. In this way the meshes for particular time steps are suboptimal, but the number of adaptive iterations performed in each time step significantly decreases.

In higher-order finite element method we have two questions. First question is which elements can be coarsened and second is how to coarsen them. In $hp$-FEM we can either decrease the polynomial order of the element or derefine the element geometrically. We can also employ various choices for assigned polynomial order. Situation is depicted in Fig. \ref{fig:coarse}. 

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.7\textwidth]{img/coarsening.pdf}
  \caption{Coarsening choices for an element.}
  \label{fig:coarse}
\end{figure}

However, the coarsening serves only to prepare the mesh for the next adaptive process, thus we do not have to search for the best unrefinement as we do in case of refinements. It is perfectly sufficient to perform any coarsening that does not cause error increase and the mesh will optimize itself in the next adaptive loop.
So far, to keep the algorithm reasonably simple we allow only coarsening as reversing of previous element refinements. In this way the tree-like structure of meshes starting from the {\em master mesh} is preserved. Unfortunately, the coarsening algorithm cannot be just an opposite to the refining. While with the refining algorithm we are seeking for the best candidate in the sense of error decrease, here we are looking for a candidate whose error will not exceed some tolerance (so that it would not be subsequently refined).

Let us denote by $e_{max}$ the error of the element with maximal error from the last adaptive iteration. From Alg. \ref{alg:adapt} from Chapter \ref{ch:adapt} we know that errors of all elements are below $ERR_{max}$ and that it should be satisfied as well after the coarsening procedure. First we calculate so called {\em super-coarse solution} for polynomial orders. By that we mean that polynomial order on all elements is decreased by one. We calculate error estimates for all elements in the super-coarse mesh with respect to the reference solution and lower the polynomial order on those elements whose error after coarsening is less than $k * ERR_{max}$, where parameter $k\in(0,1)$ is chosen to ensure that element will not be subsequently refined in the adaptive procedure on the next time level. Similar procedure is run for a spatial coarsening -- {\em super-coarse solution} is calculated on the mesh where all elements with four active subelements are coarsened and polynomial order on such elements is assigned to be the maximum of orders on four subelements. In a similar way as before we determine which elements can be also spatially unrefined without significant increase of the error.

The whole procedure for time-dependent problems with the refining and coarsening strategy is described in Alg. \ref{alg:dynamic}. Effectivity of the approach is demonstrated on the numerical examples in the last chapter of this thesis.

\begin{algorithm}[!ht]
  \caption{Adaptive algorithm for time-dependent problems with improved stopping criterion.}
\label{alg:dynamic}
  \SetAlgoLined
  \ForEach{time level}{
    \Repeat{not done}{
       compute reference solution $u_{ref}$\;
       project to get a solution on current mesh $u$\;
       evaluate global error estimate $ERR_{gl}$ and local errors on elements $ERR_i$\;
       \eIf{$ERR_{gl} < TOL$}{
          done = true\;
          break\;
          }{
          sort all elements by their error\;
          processed error = 0\;
         \ForEach{element}{
         \eIf{(processed error $> c * (ERR_{gl}$ - TOL)) \textbf{or} ($ERR_i < k * ERR_{max}$)}{
           done = true\;
           break\;
         }{
           find optimal refinement\;
           processed error $+= ERR_i$\;
         }
         }
       }
    }
    calculate super-coarse solution for polynomial orders\;
    decrease polynomial orders when possible\;
    calculate super-coarse solution for spatial refinements\;
    geometrically coarsen elements when possible\;
  }
\end{algorithm}
