In the implementation, we take the elements $K \in T_h$, of the triangulation $T_h$ to be rectangular hexahedra (rectangular parallelepipeds).
\section{Numerical integration}
Evaluation of the integral values in \ref{Linear1}, \ref{Linear2} is performed using the \textit{Gaussian numerical quadrature}. A quadrature rule approximates the integral values by replacing the integral as a weighted sum of integrand values at specified points in the domain of integration. The Gaussian quadrature is constructed so that the approximation is exact for polynomials of degree 2\textit{n} - 1 (and less). This is acceptable, as our space $V_h$ is constructed using polynomials - see section \ref{section:Vh} on the page \pageref{section:Vh}. We only need to take the value $n$ to be corresponding to the value of $p_m$ for the element $K_m$. The rule for both a 2-dimensional element face $\Gamma$, and a 3-dimensional cube $K$ is derived from a one-dimensional approximation (where the interval $\left[-1, 1\right]$ is a convention):
$$
\int_{-1}^1 f(x)\,dx = \sum_{i=1}^n w_i f(x_i)
$$
in the following way:
$$
\int_{\Gamma} f\lo\bfx\ro\,dx = \int_{-1}^{1}\int_{-1}^{1} f\lo x_1, x_2\ro\,dx \approx \sum_{i=1}^n\sum_{j=1}^n w_i w_j f\lo x_{1i}, x_{2j}\ro,
$$
$$
\int_{K} f\lo\bfx\ro\,dx = \int_{-1}^{1}\int_{-1}^{1}\int_{-1}^{1} f\lo x_1, x_2, x_3\ro\,dx \approx \sum_{i=1}^n\sum_{j=1}^n\sum_{k=1}^n w_i w_j w_k f\lo x_{1i}, x_{2j}, x_{3k}\ro,
$$
and transformation to a generic rectangular hexahedron (rectangular parallelepiped) is performed using the transformation in one dimension:
$$
\int_a^b f(x)\,dx \approx \frac{b-a}{2} \int_{-1}^1 f\left(\frac{b-a}{2}x + \frac{a+b}{2}\right)\,dx.
$$
Applying the Gaussian quadrature rule then results in the following one-dimensional approximation:
$$
\int_a^b f(x)\,dx \approx \frac{b-a}{2} \sum_{i=1}^n w_i f\left(\frac{b-a}{2}x_i + \frac{a+b}{2}\right).
$$
And the transformations in higher dimensions follow naturally. For $\Gamma = \left[a_1, b_1\right] \times \left[a_2, b_2\right]$ we have:
$$
\int_{\Gamma} f(x)\,d\bfx \approx \frac{b_2-a_2}{2}\frac{b_1-a_1}{2} \sum_{i=1}^n \sum_{j=1}^n w_i w_j f\lo\frac{b_1-a_1}{2}x_i + \frac{a_1+b_1}{2},\frac{b_2-a_2}{2}x_j + \frac{a_2+b_2}{2}\ro.
$$
Taking now e.g. \ref{Linear1}, and using the transformation, we can write (omitting the operand $\bfx = \lo x_1, x_2, x_3\ro$):
\begin{eqnarray}
a_{lm} & = & \sum_{K_i \in T_h}\int_{K_i} \left[\mrvhl - \tau\mrA\lo{\mrPsi_h^{k}}\ro \lo\nabla \cdot \mrvhl\ro\right] \mrvhm, \\
a_{lm} & := & \sum_{K_i \in T_h}\int_{K_i} f\lo\mrvhl\lo\bfx\ro, \mrvhm\lo\bfx\ro\ro , \\
a_{lm} & \approx & \sum_{K_i \in T_h} \sum_{\bfj=\overrightarrow{1}}^{\overrightarrow{n}} f\lo\mrvhl\lo\bfx_{\bfj}\ro, \mrvhm\lo\bfx_{\bfj}\ro\ro\,w_{\bfj},\label{Final_Integration_Fn}
\end{eqnarray}
where $\bfj$ is a multi-index representing sum over integration points $\bfx_j$ in three dimensions.

Based on this, we can define
\begin{eqnarray}
\label{singleNumIntA}
a_{lm K_i \bfj} & = & f\lo\mrvhl\lo\bfx_{\bfj}\ro, \mrvhm\lo\bfx_{\bfj}\ro\ro\,w_{\bfj},\\
\label{singleNumIntB}
b_{l K_i \bfj} & = & g\lo\mrvhl\lo\bfx_{\bfj}\ro\ro\,w_{\bfj},
\end{eqnarray}
where $g$ for $b_l$ can be defined similarly as $f$ for $a_lm$ in \ref{Final_Integration_Fn}.

\subsubsection{Reference element, edge}
In code, all transformations are done with the use of so-called \textit{reference element, reference edge}, which are of the "standardized" dimensions, i.e.:
\begin{eqnarray}
K_{ref} & = & \left[-1, 1\right]^{3},\\
\Gamma_{ref} & = & \left[-1, 1\right]^{2},
\end{eqnarray}
and for $K \in T_h$, $\Gamma \in \Gamma_B, \Gamma_I$ we use the reference mappings:
\begin{eqnarray}
J_K & : & K \leftrightarrow K_{ref},\\
J_\Gamma & : & \Gamma \leftrightarrow \Gamma_{ref}.
\end{eqnarray}


\subsection{Assembling the algebraic problem}
Now we have a clear expression how to evaluate the integral values \ref{Linear1}, \ref{Linear2} using \ref{singleNumIntA}, \ref{singleNumIntB}, but we need to construct the matrix $A$ (\ref{Linear3}), and the right-hand-side vector $b$ (\ref{Linear4}) in an effective manner.
This is generally achieved through a \textit{element-wise} assembling of these structures. Key to this is to create a data structure that identifies for a particular element $K_i$ all the test functions $\mrvhl$ that make sense to be evaluated (have non-empty support) on $K_i$, i.e. we are looking for the set
\be
\mrvh \lo K_i \ro = \left\{\mrvh \in V_h : supp\lo\mrvh\ro \cap K_i \neq \emptyset \right\},
\ee
and do the same for the faces $\Gamma_i$ (both boundary, and internal):
\be
\mrvh \lo \Gamma_i \ro = \left\{\mrvh \in V_h : supp\lo\mrvh\ro \cap \Gamma_i \neq \emptyset \right\}.
\ee
Now the assembling procedure looks like this:\\
\begin{algorithm}[H]
    \# Loop over elements\\
    \ForEach{$K\in T_h$}{
       \KwData{Integration points $\left\{\bfx_1, ..., \bfx_{n}\right\}$}
       \KwData{Jacobian of the mapping $J_K$}
       \KwData{Integration weights $\left\{w_1, ..., w_{\bfn}\right\}$}
                   \# Loop over integration points\\
       \ForEach{$\bfj \in \left\{1, ..., \bfn\right\}$}{
           \textbf{Set: }$JxW_{\bfj} = J_K\lo\bfx_{\bfj}\ro \times w_{\bfj}$\\
            \# Loop over test functions\\
        \ForEach{$v\in v_h \lo K \ro$}{
       \KwData{$l$ - index of $v$ in the global system, i.e. row in \ref{Linear3} - \ref{Linear5}}
                        \# Loop over basis functions\\
            \ForEach{$u\in v_h \lo K \ro$}{
       \KwData{$m$ - index of $u$ in the global system, i.e. column in \ref{Linear3}}
                
                        $a_{lm} += JxW_{\bfj} \ a_{lm K \bfj}$
                    }

                $b_{l} += JxW_{\bfj} \ b_{l K \bfj}$
        }
                            
        }
    }
\caption{Asembling of the algebraic problem \ref{Alg}}
\label{algorithm:singleTimeStep}
\end{algorithm}



